{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading an ONNX model to deepmirror\n",
    "\n",
    "Before running this notebook, please ensure you:\n",
    "\n",
    "1. Are logged in by running `dm login EMAIL` in the terminal\n",
    "2. Have a Token registered and saved on the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepmirror\n",
    "# !dm login <YOUREMAIL>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import onnx\n",
    "import pandas as pd\n",
    "from onnx import TensorProto, helper\n",
    "\n",
    "import deepmirror.api as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an exmaple onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_model(\n",
    "    ir_version: int = 10, opset_version: int = 22, input_dim: int = 1024\n",
    ") -> onnx.ModelProto:\n",
    "    X = helper.make_tensor_value_info(\n",
    "        \"input\", TensorProto.FLOAT, [1, input_dim]\n",
    "    )\n",
    "    Y = helper.make_tensor_value_info(\"output\", TensorProto.FLOAT, [1])\n",
    "    node = helper.make_node(\"Identity\", inputs=[\"input\"], outputs=[\"output\"])\n",
    "    graph = helper.make_graph([node], \"test\", [X], [Y])\n",
    "    model = helper.make_model(\n",
    "        graph,\n",
    "        ir_version=ir_version,\n",
    "        opset_imports=[helper.make_operatorsetid(\"\", opset_version)],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_onnx_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix=\".onnx\") as temp_file:\n",
    "    onnx.save(model, temp_file.name)\n",
    "    model = api.upload_onnx_model(temp_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"C[C@H](C(=O)O)[C@@H](NC(=O)c1ncnc2[nH]ccc12)c1ccc(Br)cc1\",\n",
    "    \"CC(C)[C@H](Nc1ncnc(N)c1Cl)c1ccc2c(c1)S(=O)(=O)CCC2\",\n",
    "    \"CNC(=O)c1cc2c(N[C@H](c3ccc4c(c3)OCCO4)C(C)C)ncnc2[nH]1\",\n",
    "    \"CC(C)[C@@H](Nc1ncnc2[nH]c(-c3cnn(C)c3C#N)cc12)c1ccc2c(c1)OCCO2\",\n",
    "    \"CNC(=O)CN1C[C@@]2(C(=O)N(c3cncc4ccccc34)C[C@@H]2Cc2nn[nH]n2)c2cc(Cl)ccc2C1=O\",\n",
    "    \"O=C(Nc1cccc(B(O)O)c1)[C@H]1CCN(Cc2ccccc2)C1\",\n",
    "    \"O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl\",\n",
    "    \"O=C(Nc1ccc2c(c1)CNC2)c1cc(Br)cc2[nH]c(-c3ccccc3)nc12\",\n",
    "    \"CC(C)[C@H](Nc1ncnc2[nH]cc(C(N)=O)c12)c1ccc2c(c1)OCCO2\",\n",
    "    \"CC(C)[C@H](Nc1ncnc2[nH]c(-c3cncc(S(C)(=O)=O)c3)cc12)c1ccc2c(c1)S(=O)(=O)CCC2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = api.predict(model_name=model[\"model_name\"], smiles=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
